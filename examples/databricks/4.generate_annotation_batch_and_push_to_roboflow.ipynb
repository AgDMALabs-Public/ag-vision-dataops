{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "%pip install git+https://github.com/AgDMALabs-Public/ag-vision-dataops.git",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from roboflow import Roboflow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Assumes you have a SparkSession named 'spark' available\n",
    "spark = SparkSession.builder.getOrCreate()"
   ],
   "id": "7fe59199d8624059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ag_vision.data_io import roboflow_io as rio\n",
    "from ag_vision.data_io import annotation_io as aio"
   ],
   "id": "190d7b8528c2d310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "imgs_df = spark.table(\"use1_prod_artemis_catalog_3718194974443840.production.images_table\").toPandas()",
   "id": "ffd080b86d27c1f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This is the API key needed to push data to Roboflow. Go to roboflow, settings, account, select a workspace, look for API keys. Use the Private API key. This should be stored in a secreats file.\n",
    "api_key = \"\"\n",
    "\n",
    "# This is the CG workspace, if you are working from a different workspace you will nned to change this.\n",
    "rf_workspace = \"cgiar-workspace\"\n",
    "\n",
    "# This is the project that you will push the images to. If you want to push to a new project, you need to create that project in Roboflow first, copy the name and paste it here.\n",
    "rf_project = \"crop_type_classification-g9ywv\"\n",
    "\n",
    "# This is the path to the data in databricks, change based on the location of your project.\n",
    "project_path = \"/Volumes/use1_prod_artemis_catalog_3718194974443840/production/data/artemis\"\n",
    "\n",
    "# The annotation type should be in this list ...['object_detection', 'instance_segmentation', 'classification', 'semantic_segmentation']\n",
    "annotation_type='classification'\n",
    "# This is the name of the task, that you want to build a model for.\n",
    "task_name='crop_type_classification'\n",
    "# This is the name of the batch of images that you are pushing. I usually just use the task name and then add the date the images are pushed. But if you are labeling a test set, you may want to put 'test' in the batch name. In the end many batches will be pushed per task.\n",
    "batch_name='crop_type_classification_8-28-2025'\n",
    "\n",
    "rf = Roboflow(api_key=api_key)\n",
    "project = rf.workspace(rf_workspace).project(rf_project)"
   ],
   "id": "73072be4bf8f584a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Look at the images available for labeling\n",
    "imgs_df.head()"
   ],
   "id": "22c6bec7c6422ecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add in other columns to select images from",
   "id": "147b55785e5e2fe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imgs_df = imgs_df[~imgs_df['metadata_path'].isna()]\n",
    "imgs_df.loc[:, 'grouped_exposure'] = imgs_df['exposure'].round(-1)"
   ],
   "id": "ee3222795d1c9120",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Develop logic to select images for annotating.",
   "id": "49ce1b3a7d35ef5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotation_df_list = []\n",
    "sample_size = 2\n",
    "\n",
    "for idx, df in imgs_df.groupby(['season', 'trial', 'protocol', 'grouped_exposure', 'orientation']):\n",
    "    print(idx)\n",
    "    if len(df) < sample_size:\n",
    "        annotation_df_list.append(df)\n",
    "    else:\n",
    "        annotation_df_list.append(df.sample(sample_size))\n",
    "\n",
    "annotation_df = pd.concat(annotation_df_list)\n",
    "annotation_df.head()\n",
    "print(len(annotation_df))"
   ],
   "id": "dcd6bbb9b39e0fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Look at your data.",
   "id": "eafe50b116c1a230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "annotation_df['exposure'].hist()\n",
    "plt.show()"
   ],
   "id": "34e2b3e3b82ecdfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create an annotation batch.\n",
    "* This Saves the images in the annotation folder, gives the image an new UUID, makes a metadata file."
   ],
   "id": "8d90aa694018404d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aio.create_annotation_batch(img_list=annotation_df['image_path'].tolist(),\n",
    "                            project_path=project_path,\n",
    "                            annotation_type=annotation_type,\n",
    "                            task_name=task_name,\n",
    "                            batch_name=batch_name)"
   ],
   "id": "fac5dee3b8c56d3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation\n",
    "* At this point if you need to augment the images you can read them in from the batch augment them and then save them back to the annotation folder."
   ],
   "id": "d2b61d85ebd6e4d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# logic to augment the images, resize, crop, tile and make more images... just make sure there is one image",
   "id": "3e7d2b333603d9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Push the batch up to Roboflow.\n",
    "* Roboflow will do automatic dedup, so it it fails you can just rerun the code and they will deal with the duplicate images."
   ],
   "id": "d8d47a2fed6f40fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Roboflow will check for duplicate images and skip them on upload. That is why we have some missing images in RF.\n",
    "rio.upload_image_batch_to_roboflow(rf_project=project,\n",
    "                                   project_path=project_path,\n",
    "                                   annotation_type=annotation_type,\n",
    "                                   task_name=task_name,\n",
    "                                   batch_name=batch_name,\n",
    "                                   split='train',\n",
    "                                   tmp_copy = True)"
   ],
   "id": "cd9f67ac9f1c3c0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Label, train, then download\n",
   "id": "6016439189d89910"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
