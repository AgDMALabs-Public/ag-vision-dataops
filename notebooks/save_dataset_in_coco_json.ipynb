{
 "cells": [
  {
   "cell_type": "code",
   "id": "f7292ce1-0fe6-409d-b15b-6a7c5208c845",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-21T20:44:27.766376Z",
     "start_time": "2025-08-21T20:44:27.763671Z"
    }
   },
   "source": [
    "import os\n",
    "import roboflow"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c8dfaebf-4d11-4d71-90e6-b5fd0ae97fc7",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-21T20:44:28.458109Z",
     "start_time": "2025-08-21T20:44:28.453135Z"
    }
   },
   "source": [
    "def download_dataset(api_key, workspace, project_name, version, dataset_dir=\"test_sets\"):\n",
    "    \"\"\"\n",
    "    Downloads the coco formatted dataset from Roboflow.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): Roboflow API key.\n",
    "        workspace (str): Roboflow workspace name.\n",
    "        project_name (str): Roboflow project name.\n",
    "        version (int): The version of the dataset to download.\n",
    "        dataset_dir (str): The directory where the dataset will be downloaded.\n",
    "    Returns:\n",
    "        str: The path to the downloaded dataset.\n",
    "    \"\"\"    \n",
    "    complete_dataset_dir = os.path.join(dataset_dir, f\"{project_name}-{version}\")\n",
    "    print(\"complete_dataset_dir: \", complete_dataset_dir)\n",
    "    if os.path.exists(complete_dataset_dir):\n",
    "        print(f\"Dataset already available at: {complete_dataset_dir}\")\n",
    "        # os.chdir(dataset_dir)\n",
    "        return complete_dataset_dir\n",
    "    else:\n",
    "        print(f\"Downloading dataset from Roboflow: {project_name} v{version}...\")\n",
    "        os.makedirs(dataset_dir, exist_ok=True)\n",
    "        os.chdir(dataset_dir)\n",
    "\n",
    "        rf = roboflow.Roboflow(api_key=api_key)\n",
    "        project = rf.workspace(workspace).project(project_name)\n",
    "        dataset = project.version(version).download(\"coco\")\n",
    "\n",
    "        # Roboflow downloads the dataset into a subfolder named after the project and version\n",
    "        data_path = os.path.join(dataset.location)\n",
    "        print(f\"Dataset downloaded to: {dataset.location}\")\n",
    "        return data_path"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e7862a-615b-4180-ae26-f9a0bfb0da04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROBOFLOW_API_KEY = \"\"\n",
    "ROBOFLOW_WORKSPACE = \"\"\n",
    "ROBOFLOW_PROJECT = \"merged_1_to_10_flower_inst_segmentation_batches-ixjoz\"\n",
    "ROBOFLOW_VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0beff5b7-3a62-4d3b-8a01-fcbf281ca7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete_dataset_dir:  test_sets/merged_1_to_10_flower_inst_segmentation_batches-ixjoz-2\n",
      "Downloading dataset from Roboflow: merged_1_to_10_flower_inst_segmentation_batches-ixjoz v2...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Exporting format coco in progress : 85.0%\n",
      "Version export complete for coco format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in merged_1_to_10_flower_inst_segmentation_batches-2 to coco:: 100%|██████████| 1845681/1845681 [00:21<00:00, 87264.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to merged_1_to_10_flower_inst_segmentation_batches-2 in coco:: 100%|██████████| 897/897 [00:03<00:00, 257.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /home/jupyter/inference/test_sets/merged_1_to_10_flower_inst_segmentation_batches-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/inference/test_sets/merged_1_to_10_flower_inst_segmentation_batches-2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = download_dataset(ROBOFLOW_API_KEY, ROBOFLOW_WORKSPACE, ROBOFLOW_PROJECT, ROBOFLOW_VERSION)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd66b24-5d40-43d6-a1d8-52687cffa7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcb46d-b4a1-4c37-8d25-3685dda8d4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
